apt-get install ubuntu-cloud-keyring
echo "deb http://ubuntu-cloud.archive.canonical.com/ubuntu" \
"trusty-updates/juno main" > /etc/apt/sources.list.d/cloudarchive-juno.list
apt-get update && apt-get dist-upgrade -y


auto eth0
iface eth0 inet manual
	up ifconfig $IFACE 0.0.0.0 up
	down ifconfig $IFACE down


auto br-ex
iface br-ex inet static
        address 192.168.174.140
        netmask 255.255.255.0
        gateway 192.168.174.2
        dns-nameservers 8.8.8.8
========================================================================================
apt-get install mariadb-server python-mysqldb -y

vim /etc/mysql/my.cnf
bind-address            =  0.0.0.0
default-storage-engine = innodb
innodb_file_per_table
collation-server = utf8_general_ci
init-connect = 'SET NAMES utf8'
character-set-server = utf8

service mysql restart
mysql_secure_installation

root / 1beb4be8df360c2dc05b
putao_save /c7911a1a938a0b7bc9ef

cinder glance keystone  mysql neutron nova      

========================================================================================
apt-get install rabbitmq-server -y
rabbitmqctl change_password guest guest
rabbitmqctl status | grep rabbit
vim /etc/rabbitmq/rabbitmq.config
[{rabbit, [{loopback_users, []}]}].

service rabbitmq-server restart

========================================================================================
mysql -u root -p111111
CREATE DATABASE keystone;
GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'localhost' \
IDENTIFIED BY '3b00031252bf4bf34ecc';
GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'%' \
IDENTIFIED BY '3b00031252bf4bf34ecc';
flush privileges;

openssl rand -hex 10
86d1a11c3ff724044538

apt-get install keystone python-keystoneclient -y
grep -v '^$' /etc/keystone/keystone.conf|grep -v '^#'

[DEFAULT]
admin_token = 86d1a11c3ff724044538
verbose = True

[database]
connection = mysql://keystone:3b00031252bf4bf34ecc@controller/keystone

[token]
provider = keystone.token.providers.uuid.Provider
driver = keystone.token.persistence.backends.sql.Token

[revoke]
driver = keystone.contrib.revoke.backends.sql.Revoke

su -s /bin/sh -c "keystone-manage db_sync" keystone

service keystone restart

rm -f /var/lib/keystone/keystone.db
(crontab -l -u keystone 2>&1 | grep -q token_flush) || \
echo '@hourly /usr/bin/keystone-manage token_flush >/var/log/keystone/keystone-tokenflush.log 2>&1' \
>> /var/spool/cron/crontabs/keystone

export OS_SERVICE_TOKEN=86d1a11c3ff724044538
export OS_SERVICE_ENDPOINT=http://controller:35357/v2.0

keystone tenant-create --name admin --description "Admin Tenant"
keystone user-create --name admin --pass 33a6f4f22eb7e48fb20a --email tianyk@putao.com      新修改的密码:af3f30cd16c3ce063818!@^*1
keystone role-create --name admin
keystone user-role-add --user admin --tenant admin --role admin

keystone tenant-create --name demo --description "Demo Tenant"
keystone user-create --name demo --tenant demo --pass 861f69a9a3d81221cf18 --email tianyk@putao.com
keystone tenant-create --name service --description "Service Tenant"


keystone service-create --name keystone --type identity \
--description "OpenStack Identity"

keystone endpoint-create \
--service-id $(keystone service-list | awk '/ identity / {print $2}') \
--publicurl http://controller:5000/v2.0 \
--internalurl http://controller:5000/v2.0 \
--adminurl http://controller:35357/v2.0 \
--region regionOne


unset OS_SERVICE_TOKEN OS_SERVICE_ENDPOINT
keystone --os-tenant-name admin --os-username admin --os-password 33a6f4f22eb7e48fb20a \
--os-auth-url http://controller:35357/v2.0 token-get


keystone --os-tenant-name admin --os-username admin --os-password 33a6f4f22eb7e48fb20a \
--os-auth-url http://controller:35357/v2.0 tenant-list

keystone --os-tenant-name admin --os-username admin --os-password 33a6f4f22eb7e48fb20a \
--os-auth-url http://controller:35357/v2.0 user-list

keystone --os-tenant-name admin --os-username admin --os-password 33a6f4f22eb7e48fb20a \
--os-auth-url http://controller:35357/v2.0 role-list


vim admin-openrc.sh
vim demo-openrc.sh
export OS_TENANT_NAME=admin
export OS_USERNAME=admin
export OS_PASSWORD=33a6f4f22eb7e48fb20a
export OS_AUTH_URL=http://controller:35357/v2.0


export OS_TENANT_NAME=demo
export OS_USERNAME=demo
export OS_PASSWORD=861f69a9a3d81221cf18
export OS_AUTH_URL=http://controller:5000/v2.0

========================================================================================
mysql -u root -p111111
CREATE DATABASE glance;
GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'localhost' \
IDENTIFIED BY 'a207fa39ce55fb6ae05f';
GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'%' \
IDENTIFIED BY 'a207fa39ce55fb6ae05f';
flush privileges;

source admin-openrc.sh
keystone user-create --name glance --pass 001d4a1239df7d00264d
keystone user-role-add --user glance --tenant service --role admin
keystone service-create --name glance --type image \
--description "OpenStack Image Service"

keystone endpoint-create \
--service-id $(keystone service-list | awk '/ image / {print $2}') \
--publicurl http://controller:9292 \
--internalurl http://controller:9292 \
--adminurl http://controller:9292 \
--region regionOne

apt-get install glance python-glanceclient -y


grep -v '^$' /etc/glance/glance-api.conf|grep -v '^#'
/etc/glance/glance-api.conf
[database]
connection = mysql://glance:a207fa39ce55fb6ae05f@controller/glance

[keystone_authtoken]
auth_uri = http://controller:5000/v2.0
identity_uri = http://controller:35357
admin_tenant_name = service
admin_user = glance
admin_password = 001d4a1239df7d00264d

[paste_deploy]
flavor = keystone

[glance_store]
default_store = file
filesystem_store_datadir = /var/lib/glance/images/

[DEFAULT]
notification_driver = noopverbose = True

/etc/glance/glance-registry.conf
[database]
connection = mysql://glance:a207fa39ce55fb6ae05f@controller/glance

[keystone_authtoken]
auth_uri = http://controller:5000/v2.0
identity_uri = http://controller:35357
admin_tenant_name = service
admin_user = glance
admin_password = 001d4a1239df7d00264d

[paste_deploy]
flavor = keystone

[DEFAULT]
notification_driver = noopverbose = True

su -s /bin/sh -c "glance-manage db_sync" glance
service glance-registry restart
service glance-api restart
rm -f /var/lib/glance/glance.sqlite


glance image-create --name "cirros-0.3.3-x86_64" --file cirros-0.3.3-x86_64-disk.img \
--disk-format qcow2 --container-format bare --is-public True --progress

glance image-create --name "debian-8.0.0" --file debian-8.0.0-openstack-amd64.qcow2 \
--disk-format qcow2 --container-format bare --is-public True --progress


glance image-create --name "debian_wheezy_7.8" --file debian_wheezy_mips_standard.qcow2 \
--disk-format qcow2 --container-format bare --is-public True --progress

===========================================================================================
mysql -u root -p111111
CREATE DATABASE nova;
GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'localhost' \
IDENTIFIED BY '51e108f58ce046098634';
GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'%' \
IDENTIFIED BY '51e108f58ce046098634';
flush privileges;


source admin-openrc.sh
keystone user-create --name nova --pass 7d61a20ff154d08ce317
keystone user-role-add --user nova --tenant service --role admin
keystone service-create --name nova --type compute \
--description "OpenStack Compute"
keystone endpoint-create \
--service-id $(keystone service-list | awk '/ compute / {print $2}') \
--publicurl http://controller:8774/v2/%\(tenant_id\)s \
--internalurl http://controller:8774/v2/%\(tenant_id\)s \
--adminurl http://controller:8774/v2/%\(tenant_id\)s \
--region regionOne

apt-get install nova-api nova-cert nova-conductor nova-consoleauth \
nova-novncproxy nova-scheduler python-novaclient -y

/etc/nova/nova.conf
[database]
connection = mysql://nova:51e108f58ce046098634@controller/nova

[DEFAULT]
rpc_backend = rabbit
rabbit_host = controller
rabbit_password = guest
auth_strategy = keystone
my_ip = 172.20.0.154
vncserver_listen = 172.20.0.154
vncserver_proxyclient_address = 172.20.0.154
verbose = True

[keystone_authtoken]
auth_uri = http://controller:5000/v2.0
identity_uri = http://controller:35357
admin_tenant_name = service
admin_user = nova
admin_password = 7d61a20ff154d08ce317

[glance]
host = controller

su -s /bin/sh -c "nova-manage db sync" nova
service nova-api restart
service nova-cert restart
service nova-consoleauth restart
service nova-scheduler restart
service nova-conductor restart
service nova-novncproxy restart

rm -f /var/lib/nova/nova.sqlite


apt-get install nova-compute sysfsutils python-guestfs -y
/etc/nova/nova.conf 
[DEFAULT]
vnc_enabled = True
vncserver_listen = 0.0.0.0
vncserver_proxyclient_address = 172.20.0.153
novncproxy_base_url = http://122.226.100.154:6080/vnc_auto.html

egrep -c '(vmx|svm)' /proc/cpuinfo
/etc/nova/nova-compute.conf
[libvirt]
virt_type = qemu
service nova-compute restart

source admin-openrc.sh

nova service-list


===========================================================================================
mysql -u root -p111111
CREATE DATABASE neutron;
GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'localhost' \
IDENTIFIED BY '8dc220435976ed9589da';
GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'%' \
IDENTIFIED BY '8dc220435976ed9589da';
flush privileges;

source admin-openrc.sh
keystone user-create --name neutron --pass bb71b090434a7098da64
keystone user-role-add --user neutron --tenant service --role admin
keystone service-create --name neutron --type network \
--description "OpenStack Networking"

keystone endpoint-create \
--service-id $(keystone service-list | awk '/ network / {print $2}') \
--publicurl http://controller:9696 \
--adminurl http://controller:9696 \
--internalurl http://controller:9696 \
--region regionOne

apt-get install neutron-server neutron-plugin-ml2 python-neutronclient -y

/etc/neutron/neutron.conf 
[database]
connection = mysql://neutron:8dc220435976ed9589da@controller/neutron

[DEFAULT]
rpc_backend = rabbit
rabbit_host = controller
rabbit_password = guest
auth_strategy = keystone

core_plugin = ml2
service_plugins = router
allow_overlapping_ips = True

notify_nova_on_port_status_changes = True
notify_nova_on_port_data_changes = True
nova_url = http://controller:8774/v2
nova_admin_auth_url = http://controller:35357/v2.0
nova_region_name = regionOne
nova_admin_username = nova
nova_admin_tenant_id = 6dcaf49d190647eaaaadd18205d76bee
nova_admin_password = 7d61a20ff154d08ce317
verbose = True

####source admin-openrc.sh
####keystone tenant-get service

[keystone_authtoken]
auth_uri = http://controller:5000/v2.0
identity_uri = http://controller:35357
admin_tenant_name = service
admin_user = neutron
admin_password = bb71b090434a7098da64


/etc/neutron/plugins/ml2/ml2_conf.ini
[ml2]
type_drivers = flat,gre
tenant_network_types = gre
mechanism_drivers = openvswitch

[ml2_type_gre]
tunnel_id_ranges = 1:1000

[securitygroup]
enable_security_group = True
enable_ipset = True
firewall_driver = neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver


/etc/nova/nova.conf
[DEFAULT]
network_api_class = nova.network.neutronv2.api.API
security_group_api = neutron
linuxnet_interface_driver = nova.network.linux_net.LinuxOVSInterfaceDriver
firewall_driver = nova.virt.firewall.NoopFirewallDriver

[neutron]
url = http://controller:9696
auth_strategy = keystone
admin_auth_url = http://controller:35357/v2.0
admin_tenant_name = service
admin_username = neutron
admin_password = bb71b090434a7098da64


su -s /bin/sh -c "neutron-db-manage --config-file /etc/neutron/neutron.conf \
--config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade juno" neutron

service nova-api restart
service nova-scheduler restart
service nova-conductor restart
service neutron-server restart

neutron ext-list

/etc/sysctl.conf
net.ipv4.ip_forward=1
net.ipv4.conf.all.rp_filter=0
net.ipv4.conf.default.rp_filter=0
sysctl -p

apt-get install neutron-plugin-ml2 neutron-plugin-openvswitch-agent \
neutron-l3-agent neutron-dhcp-agent -y

/etc/neutron/plugins/ml2/ml2_conf.ini

[ml2_type_flat]
flat_networks = external

[ovs]
local_ip = controller
enable_tunneling = True
bridge_mappings = external:br-ex

[agent]
tunnel_types = gre

/etc/neutron/l3_agent.ini
[DEFAULT]
interface_driver = neutron.agent.linux.interface.OVSInterfaceDriver
use_namespaces = True
external_network_bridge = br-ex
router_delete_namespaces = True
verbose = True

/etc/neutron/dhcp_agent.ini
[DEFAULT]
interface_driver = neutron.agent.linux.interface.OVSInterfaceDriver
dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq
use_namespaces = True
dhcp_delete_namespaces = True
verbose = True
dnsmasq_config_file = /etc/neutron/dnsmasq-neutron.conf

/etc/neutron/dnsmasq-neutron.conf
dhcp-option-force=26,1454

pkill dnsmasq


openssl rand -hex 10
09d09fed58e149aa96ea
/etc/neutron/metadata_agent.ini
[DEFAULT]
auth_url = http://controller:5000/v2.0
auth_region = regionOne
admin_tenant_name = service
admin_user = neutron
admin_password = bb71b090434a7098da64

nova_metadata_ip = controller

metadata_proxy_shared_secret = 09d09fed58e149aa96ea
verbose = True

/etc/nova/nova.conf
service_metadata_proxy = True
metadata_proxy_shared_secret = 09d09fed58e149aa96ea
service nova-api restart


service openvswitch-switch restart
ovs-vsctl add-br br-ex
ovs-vsctl add-port br-ex eth1

ovs-vsctl add-br br-end
ovs-vsctl add-port br-end eth0


service neutron-plugin-openvswitch-agent restart
service neutron-l3-agent restart
service neutron-dhcp-agent restart
service neutron-metadata-agent restart

service openvswitch-switch restart
update-rc.d openvswitch-switch defaults

neutron net-create ext-net --router:external True \
--provider:physical_network external --provider:network_type flat

neutron subnet-create ext-net --name ext-subnet \
--allocation-pool start=122.226.100.151,end=122.226.100.158 \
--disable-dhcp --gateway 122.226.100.145 122.226.100.144/28


neutron net-create end-net --router:external True \
--provider:physical_network endternal --provider:network_type flat

neutron subnet-create end-net --name end-subnet \
--allocation-pool start=172.20.0.180,end=172.20.0.200 \
--disable-dhcp --gateway 172.20.0.1 172.20.0.0/24



neutron net-create demo-net
neutron subnet-create demo-net --name demo-subnet \
--gateway 172.16.0.1 172.16.0.0/24

neutron net-create putao-net
neutron subnet-create putao-net --name putao-subnet \
--gateway 172.17.0.1 172.17.0.0/24

neutron router-create demo-router
neutron router-interface-add demo-router demo-subnet
neutron router-gateway-set demo-router ext-net

neutron router-create putao-router
neutron router-interface-add putao-router putao-subnet
neutron router-gateway-set putao-router end-net

/usr/bin/python /usr/bin/neutron-l3-agent --config-file=/etc/neutron/neutron.conf --config-file=/etc/neutron/l3_agent_putao.ini --config-file=/etc/neutron/fwaas_driver.ini --log-file=/var/log/neutron/l3-agent-putao.log


=================================================================================
apt-get install openstack-dashboard apache2 \
libapache2-mod-wsgi memcached python-memcache -y
/etc/openstack-dashboard/local_settings.py

OPENSTACK_HOST = "controller"

service apache2 restart
service memcached restart

glance image-create --name "cloud_ubuntu_14_04" --file trusty-server-cloudimg-amd64-disk1.img \
--disk-format qcow2 --container-format bare --is-public True --progress

glance image-create --name "debian-8.0.0" --file debian-8.0.0-openstack-amd64.qcow2 \
--disk-format qcow2 --container-format bare --is-public True --progress



glance image-create --name "cloud_cirros" --file cirros-0.3.3-x86_64-disk.img \
--disk-format qcow2 --container-format bare --is-public True --progress


glance image-create --name "cirros-0.3.3-x86_64" --file cirros-0.3.3-x86_64-disk.img \
--disk-format qcow2 --container-format bare --is-public True --progress

=====================================================================================
mysql -u root -p111111
CREATE DATABASE cinder;
GRANT ALL PRIVILEGES ON cinder.* TO 'cinder'@'localhost' \
IDENTIFIED BY '45fa8b824c6cec0b1bf1';
GRANT ALL PRIVILEGES ON cinder.* TO 'cinder'@'%' \
IDENTIFIED BY '45fa8b824c6cec0b1bf1';
flush privileges;

keystone user-create --name cinder --pass 715661a6743de7ba9661
keystone user-role-add --user cinder --tenant service --role admin
keystone service-create --name cinder --type volume \
--description "OpenStack Block Storage"
keystone service-create --name cinderv2 --type volumev2 \
--description "OpenStack Block Storage"

keystone endpoint-create \
--service-id $(keystone service-list | awk '/ volume / {print $2}') \
--publicurl http://controller:8776/v1/%\(tenant_id\)s \
--internalurl http://controller:8776/v1/%\(tenant_id\)s \
--adminurl http://controller:8776/v1/%\(tenant_id\)s \
--region regionOne

keystone endpoint-create \
--service-id $(keystone service-list | awk '/ volumev2 / {print $2}') \
--publicurl http://controller:8776/v2/%\(tenant_id\)s \
--internalurl http://controller:8776/v2/%\(tenant_id\)s \
--adminurl http://controller:8776/v2/%\(tenant_id\)s \
--region regionOne

apt-get install cinder-api cinder-scheduler python-cinderclient -y
/etc/cinder/cinder.conf
[database]
connection = mysql://cinder:45fa8b824c6cec0b1bf1@controller/cinder

[DEFAULT]
rpc_backend = rabbit
rabbit_host = controller
rabbit_password = guest
auth_strategy = keystone
my_ip = controller
verbose = True

[keystone_authtoken]
auth_uri = http://controller:5000/v2.0
identity_uri = http://controller:35357
admin_tenant_name = service
admin_user = cinder
admin_password = 715661a6743de7ba9661

su -s /bin/sh -c "cinder-manage db sync" cinder

service cinder-scheduler restart
service cinder-api restart


service cinder-scheduler stop
service cinder-api stop

rm -f /var/lib/cinder/cinder.sqlite

apt-get install lvm2

pvcreate /dev/sdd1
vgcreate cinder-volumes /dev/sdd1

/etc/lvm/lvm.conf
filter = [ "a/sdd/", "r/.*/"]

apt-get install cinder-volume python-mysqldb -y
/etc/cinder/cinder.conf
[DEFAULT]
glance_host = controller

cinder service-list

cinder create --display-name demo-volume1 1


nova boot --flavor m1.small --image "ubuntu 14.04" --nic net-id=579dc072-5b79-41e4-a82d-924a9d7eb6b6  \
--security-group default --key-name openstackn demo-instance1


service cinder-volume restart
service tgt restart

service cinder-volume stop
service tgt stop
====================================================================================
keystone user-create --name swift --pass 111111
keystone user-role-add --user swift --tenant service --role admin
keystone service-create --name swift --type object-store \
--description "OpenStack Object Storage"

keystone endpoint-create \
--service-id $(keystone service-list | awk '/ object-store / {print $2}') \
--publicurl 'http://controller:8080/v1/AUTH_%(tenant_id)s' \
--internalurl 'http://controller:8080/v1/AUTH_%(tenant_id)s' \
--adminurl http://controller:8080 \
--region regionOne


apt-get install swift swift-proxy python-swiftclient python-keystoneclient \
python-keystonemiddleware memcached -y

curl -o /etc/swift/proxy-server.conf \
https://raw.githubusercontent.com/openstack/swift/stable/juno/etc/proxy-server.conf-sample

vim /etc/swift/proxy-server.conf 
[DEFAULT]
user = swift
swift_dir = /etc/swift

[pipeline:main]
pipeline = catch_errors gatekeeper healthcheck proxy-logging authtoken keystoneauth cache container_sync bulk tempurl ratelimit tempauth container-quotas account-quotas slo dlo proxy-logging proxy-server

[app:proxy-server]
allow_account_management = true
account_autocreate = true

[filter:keystoneauth]
use = egg:swift#keystoneauth
operator_roles = admin,_member_

[filter:authtoken]
paste.filter_factory = keystonemiddleware.auth_token:filter_factory
auth_uri = http://controller:5000/v2.0
identity_uri = http://controller:35357
admin_tenant_name = service
admin_user = swift
admin_password = 111111
delay_auth_decision = true

[filter:cache]
use = egg:swift#memcache
memcache_servers = 127.0.0.1:11211

============================================================================================================================
apt-get install xfsprogs rsync -y

mkfs.xfs /dev/sdb1
mkfs.xfs /dev/sdc1

mkdir -p /srv/node/sdb1
mkdir -p /srv/node/sdc1

vim /etc/fstab
/dev/sdb1 /srv/node/sdb1 xfs noatime,nodiratime,nobarrier,logbufs=8 0 2
/dev/sdc1 /srv/node/sdc1 xfs noatime,nodiratime,nobarrier,logbufs=8 0 2

mount /srv/node/sdb1
mount /srv/node/sdc1

/etc/rsyncd.conf
uid = swift
gid = swift
log file = /var/log/rsyncd.log
pid file = /var/run/rsyncd.pid
address = controller
[account]
max connections = 2
path = /srv/node/
read only = false
lock file = /var/lock/account.lock
[container]
max connections = 2
path = /srv/node/
read only = false
lock file = /var/lock/container.lock
[object]
max connections = 2
path = /srv/node/
read only = false
lock file = /var/lock/object.lock

/etc/default/rsync
RSYNC_ENABLE=true

service rsync restart

apt-get install swift swift-account swift-container swift-object -y
curl -o /etc/swift/account-server.conf \
https://raw.githubusercontent.com/openstack/swift/stable/juno/etc/account-server.conf-sample

curl -o /etc/swift/container-server.conf \
https://raw.githubusercontent.com/openstack/swift/stable/juno/etc/container-server.conf-sample

curl -o /etc/swift/object-server.conf \
https://raw.githubusercontent.com/openstack/swift/stable/juno/etc/object-server.conf-sample

vim account-server.conf
[DEFAULT]
bind_ip = controller
bind_port = 6002
user = swift
swift_dir = /etc/swift
devices = /srv/node

[pipeline:main]
pipeline = healthcheck recon account-server

[filter:recon]
use = egg:swift#recon
recon_cache_path = /var/cache/swift


container-server.conf
[DEFAULT]
bind_ip = controller
bind_port = 6001
user = swift
swift_dir = /etc/swift
devices = /srv/node

[pipeline:main]
pipeline = healthcheck recon container-server

[filter:recon]
use = egg:swift#recon
recon_cache_path = /var/cache/swift

vim object-server.conf
[DEFAULT]
bind_ip = controller
bind_port = 6000
user = swift
swift_dir = /etc/swift
devices = /srv/node

[pipeline:main]
pipeline = healthcheck recon object-server

[filter:recon]
use = egg:swift#recon
recon_cache_path = /var/cache/swift

chown -R swift:swift /srv/node
mkdir -p /var/cache/swift
chown -R swift:swift /var/cache/swift


==========================================================================================================
cd /etc/swift
swift-ring-builder account.builder create 10 3 1

swift-ring-builder account.builder add r1z1-controller:6002/sdb1 100
swift-ring-builder account.builder add r1z1-controller:6002/sdc1 100
swift-ring-builder account.builder add r1z1-10.1.14.17:6002/sdb1 100
swift-ring-builder account.builder add r1z1-10.1.14.17:6002/sdc1 100

swift-ring-builder account.builder

swift-ring-builder account.builder rebalance





swift-ring-builder container.builder create 10 3 1

swift-ring-builder container.builder add r1z1-controller:6001/sdb1 100
swift-ring-builder container.builder add r1z1-controller:6001/sdc1 100
swift-ring-builder container.builder add r1z1-10.1.14.17:6001/sdb1 100
swift-ring-builder container.builder add r1z1-10.1.14.17:6001/sdc1 100

swift-ring-builder container.builder

swift-ring-builder container.builder rebalance



swift-ring-builder object.builder create 10 3 1

swift-ring-builder object.builder add r1z1-controller:6000/sdb1 100
swift-ring-builder object.builder add r1z1-controller:6000/sdc1 100
swift-ring-builder object.builder add r1z1-10.1.14.17:6000/sdb1 100
swift-ring-builder object.builder add r1z1-10.1.14.17:6000/sdc1 100

swift-ring-builder object.builder

swift-ring-builder object.builder rebalance



scp *.ring.gz 10.1.14.17:/etc/swift/


curl -o /etc/swift/swift.conf \
https://raw.githubusercontent.com/openstack/swift/stable/juno/etc/swift.conf-sample


openssl rand -hex 10
8c7805e5c2d67d922f0d
openssl rand -hex 10
d862360cc7d87ee77ef7

scp swift.conf  10.1.14.17:/etc/swift/
chown -R swift:swift /etc/swift


#controller node
service memcached restart
service swift-proxy restart

#stroage node
swift-init all start

swift stat

swift upload demo-container1 admin-openrc.sh 
swift list
swift download demo-container1 admin-openrc.sh

======================================================================================================================
mysql -u root -p111111
CREATE DATABASE heat;
GRANT ALL PRIVILEGES ON heat.* TO 'heat'@'localhost' \
IDENTIFIED BY '111111';
GRANT ALL PRIVILEGES ON heat.* TO 'heat'@'%' \
IDENTIFIED BY '111111';
flush privileges;

keystone user-create --name heat --pass 111111
keystone user-role-add --user heat --tenant service --role admin
keystone role-create --name heat_stack_owner
keystone user-role-add --user demo --tenant demo --role heat_stack_owner
keystone role-create --name heat_stack_user

keystone service-create --name heat --type orchestration \
--description "Orchestration"
keystone service-create --name heat-cfn --type cloudformation \
--description "Orchestration"

keystone endpoint-create \
--service-id $(keystone service-list | awk '/ orchestration / {print $2}') \
--publicurl http://controller:8004/v1/%\(tenant_id\)s \
--internalurl http://controller:8004/v1/%\(tenant_id\)s \
--adminurl http://controller:8004/v1/%\(tenant_id\)s \
--region regionOne

keystone endpoint-create \
--service-id $(keystone service-list | awk '/ cloudformation / {print $2}') \
--publicurl http://controller:8000/v1 \
--internalurl http://controller:8000/v1 \
--adminurl http://controller:8000/v1 \
--region regionOne


apt-get install heat-api heat-api-cfn heat-engine python-heatclient -y

/etc/heat/heat.conf
[database]
connection = mysql://heat:111111@controller/heat

[DEFAULT]
rpc_backend = rabbit
rabbit_host = controller
rabbit_password = guest
heat_metadata_server_url = http://controller:8000
heat_waitcondition_server_url = http://controller:8000/v1/waitcondition


[keystone_authtoken]
auth_uri = http://controller:5000/v2.0
identity_uri = http://controller:35357
admin_tenant_name = service
admin_user = heat
admin_password = 111111

[ec2authtoken]
auth_uri = http://controller:5000/v2.0

su -s /bin/sh -c "heat-manage db_sync" heat
service heat-api restart
service heat-api-cfn restart
service heat-engine restart
rm -f /var/lib/heat/heat.sqlite


vim test-stack.yml

heat_template_version: 2015-06-03
description: A simple server.

parameters:
  ImageID:
	type: string
	description: Image use to boot a server
  NetID:
	type: string
	description: Network ID for the server

resources:
  server:
	type: OS::Nova::Server
	properties:
	  image: { get_param: ImageID }
	  flavor: m1.tiny
      networks:
	  - network: { get_param: NetID }
outputs:
  private_ip:
	description: IP address of the server in the private network
	value: { get_attr: [ server, first_address ] }

NET_ID=$(nova net-list | awk '/ demo-net / { print $2 }')
heat stack-create -f test-stack.yml -P "ImageID=cirros-0.3.3-x86_64;NetID=$NET_ID" testStack



mongo --host controller --eval '
db = db.getSiblingDB("ceilometer");
db.addUser({user: "ceilometer",
pwd: "CEILOMETER_DBPASS",
roles: [ "readWrite", "dbAdmin" ]})'

keystone user-create --name ceilometer --pass 111111
keystone user-role-add --user ceilometer --tenant service --role admin
keystone service-create --name ceilometer --type metering \
--description "Telemetry"

keystone endpoint-create \
--service-id $(keystone service-list | awk '/ metering / {print $2}') \
--publicurl http://controller:8777 \
--internalurl http://controller:8777 \
--adminurl http://controller:8777 \
--region regionOne

apt-get install ceilometer-api ceilometer-collector ceilometer-agent-central \
ceilometer-agent-notification ceilometer-alarm-evaluator ceilometer-alarm-notifier \
python-ceilometerclient

[database]
connection = mongodb://ceilometer:CEILOMETER_DBPASS@controller:27017/ceilometer

